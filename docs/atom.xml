<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
	<title>Siddharth's blog</title>
	<link href="https://s1dsq.github.io/atom.xml" rel="self" />
	<updated>2025-04-28T08:23:48Z</updated>
	<author>
		<name>Siddharth Singh</name>
	</author>
	<id>https://s1dsq.github.io,2024-03-26:default-atom-feed/</id>
	<entry>
		<title>Pydantic: a simple case study</title>
		<content type="html">&lt;h1&gt;Pydantic: a simple case study&lt;/h1&gt;
&lt;p&gt;2024-04-05&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.pydantic.dev/latest/&quot;&gt;Pydantic&lt;/a&gt; is a data validation library for
python. In this post I want to contrast it with using plain python by writing a
short program&lt;/p&gt;
&lt;p&gt;We will parse the output of the &lt;a href=&quot;https://lobste.rs/hottest.json&quot;&gt;hottest&lt;/a&gt; posts
from &lt;a href=&quot;https://lobste.rs/&quot;&gt;lobste.rs&lt;/a&gt; which is a link aggregator like hackernews
focused on computing&lt;/p&gt;
&lt;p&gt;The code for this post is available
&lt;a href=&quot;https://github.com/s1dsq/pydantic-case-study&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Regular python&lt;/h2&gt;
&lt;p&gt;The hottest posts is a json array and each entry is of the following format:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-json&quot;&gt;{
    &amp;quot;short_id&amp;quot;: &amp;quot;pkgjno&amp;quot;,
    &amp;quot;short_id_url&amp;quot;: &amp;quot;https://lobste.rs/s/pkgjno&amp;quot;,
    &amp;quot;created_at&amp;quot;: &amp;quot;2024-03-30T16:16:16.000-05:00&amp;quot;,
    &amp;quot;title&amp;quot;: &amp;quot;Type Inference Was a Mistake&amp;quot;,
    &amp;quot;url&amp;quot;: &amp;quot;https://borretti.me/article/type-inference-was-a-mistake&amp;quot;,
    &amp;quot;score&amp;quot;: 36,
    &amp;quot;flags&amp;quot;: 0,
    &amp;quot;comment_count&amp;quot;: 32,
    &amp;quot;description&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;description_plain&amp;quot;: &amp;quot;&amp;quot;,
    &amp;quot;comments_url&amp;quot;: &amp;quot;https://lobste.rs/s/pkgjno/type_inference_was_mistake&amp;quot;,
    &amp;quot;submitter_user&amp;quot;: &amp;quot;puffnfresh&amp;quot;,
    &amp;quot;user_is_author&amp;quot;: false,
    &amp;quot;tags&amp;quot;: [&amp;quot;plt&amp;quot;]
},
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We want to read each entry and parse the fields of interest which is represented
as:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;@dataclass
class LobstersPost:
    created_at: datetime
    title: str
    url: str
    score: int
    comments_url: str
    tags: list[str]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is core parsing function:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;def parse_post(post: dict) -&amp;gt; typing.Union[LobstersPost, None]:
    created_at: datetime = datetime.now()
    title: str = &amp;quot;&amp;quot;
    url: str = &amp;quot;&amp;quot;
    score: int = 0
    comments_url: str = &amp;quot;&amp;quot;
    tags: list[str] = []

    try:
        errors = []
        for k, v in post.items():
            if k == &amp;quot;created_at&amp;quot;:
                try:
                    created_at = datetime.strptime(v, &amp;quot;%Y-%m-%dT%H:%M:%S.%f%z&amp;quot;)
                except ValueError as e:
                    errors.append(&amp;quot;failed to parse datetime&amp;quot; + str(e))
            elif k == &amp;quot;title&amp;quot;:
                if isinstance(v, str):
                    title = v
                else:
                    errors.append(f&amp;quot;cannot convert {type(v)} to str&amp;quot;)
            elif k == &amp;quot;url&amp;quot;:
                if isinstance(v, str):
                    url = v
                else:
                    errors.append(f&amp;quot;cannot convert {type(v)} to str&amp;quot;)
            elif k == &amp;quot;score&amp;quot;:
                if isinstance(v, int):
                    score = v
                else:
                    errors.append(f&amp;quot;cannot convert {type(v)} to int&amp;quot;)
            elif k == &amp;quot;comments_url&amp;quot;:
                if isinstance(v, str):
                    comments_url = v
                else:
                    errors.append(f&amp;quot;cannot convert {type(v)} to str&amp;quot;)
            elif k == &amp;quot;tags&amp;quot;:
                if isinstance(v, list):
                    tags = []
                    for tag in v:
                        if isinstance(tag, str):
                            tags.append(tag)
                        else:
                            errors.append(f&amp;quot;cannot convert {type(tag)} to int&amp;quot;)
                else:
                    errors.append(f&amp;quot;cannot convert {type(v)} to list[str]&amp;quot;)

        if len(errors) != 0:
            raise ValidationError(errors)
        return LobstersPost(
            created_at=created_at,
            title=title,
            url=url,
            score=score,
            comments_url=comments_url,
            tags=tags,
        )
    except ValidationError as e:
        print(e.errors())
        return None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here &lt;code&gt;ValidationError&lt;/code&gt; is a custom Exception I have defined. We are validating
each field if present and checking if the values are of the proper types, making
heavy use of the builtin function &lt;code&gt;isinstance&lt;/code&gt;. Some observations:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The parsing function is rather verbose. Imagine having many schemas all over
the codebase and writing these kinds of functions for all of them. This
quickly gets out of hand&lt;/li&gt;
&lt;li&gt;If the schema changes, we have to change the parsing function as well&lt;/li&gt;
&lt;li&gt;Nested types are a chore to validate&lt;/li&gt;
&lt;li&gt;The datetime validation does not handle different formats. That adds further
complexities&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Pydantic&lt;/h2&gt;
&lt;p&gt;Let&#39;s write the same &lt;code&gt;parse_post&lt;/code&gt; function using pydantic. We define the schema
first:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;class LobstersPost(BaseModel):
    created_at: datetime
    title: str
    url: str
    score: int
    comments_url: str
    tags: list[str]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;BaseModel&lt;/code&gt; is a part of pydantic. It is like a dataclass except it boasts more
features as advertised in the docs. Let&#39;s check the parsing function which is
laughably small:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-python&quot;&gt;def parse_post(post: dict) -&amp;gt; typing.Union[LobstersPost, None]:
    try:
        p = LobstersPost(**post)
        return p
    except ValidationError as e:
        print(e.errors())
        return None
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All our concerns with using just python are taken care of now. But here are some
cases where you may not need the powers of pydantic:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;When the data does not leave the system boundary. Simple dataclasses will do
here as the programmer guarantees the types&lt;/li&gt;
&lt;li&gt;Pydantic has many features baked in and a steeper learning curve. For simpler
use cases you may not need them&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I read &lt;a href=&quot;https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/&quot;&gt;Parse, don&#39;t
validate&lt;/a&gt; a
while back and was immediately sold on the idea but had no idea how to apply it
in languages like python.&lt;/p&gt;
&lt;p&gt;The core idea of the article is that we must transform unstructured data into
structured data only once and encode that information in the type system so that
it never needs to be checked again. In practice this means:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Choose data structures that make illegal state unrepresentable&lt;/li&gt;
&lt;li&gt;Push the burden of &lt;em&gt;validation&lt;/em&gt; at the system boundary&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Pydantic aids in our quest to validate early&lt;/p&gt;</content>
		<link href="https://s1dsq.github.io/pydantic"/>
		<id>https://s1dsq.github.io/pydantic</id>
		<updated>2024-04-05T10:00:00Z</updated>
		<published>2024-04-05T10:00:00Z</published>
	</entry>
	<entry>
		<title>Writing a primitive version of git</title>
		<content type="html">&lt;h1&gt;Writing a primitive version of git&lt;/h1&gt;
&lt;p&gt;2024-03-24&lt;/p&gt;
&lt;p&gt;Most of us use the git version control everyday. Git has a bad UI as many people
have complained on the internet before. But understanding the internals allows
us to better use this piece of software on a day to day basis. Also, it helps
demystify the &quot;magic&quot; a little bit.&lt;/p&gt;
&lt;p&gt;In this post, we will write a very basic version of git in golang that we can
push to github as a remote using the git command line. Along the way we will
understand how git stores objects on disk which is the secret sauce to the dish
that is git.&lt;/p&gt;
&lt;h2&gt;What is git?&lt;/h2&gt;
&lt;p&gt;At its core, git is a content-addressable filesystem. This means it is a key
value store on disk. You can store any content on disk and address it using a
key that git gives you. If we tap into this store and write data to it manually
using our program, we can make git think that we ran a bunch of porcelain
commands (git init, git checkout etc. Basically any user-friendly
command)&lt;/p&gt;
&lt;p&gt;Git store all of this key-value information and more in a &lt;code&gt;.git&lt;/code&gt; directory in
the root of your repository. This is automatically created when we run &lt;code&gt;git
init&lt;/code&gt; to initialize a new repository.&lt;/p&gt;
&lt;h2&gt;What?&lt;/h2&gt;
&lt;p&gt;Here is what we want to do:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Initialize a new git repository&lt;/li&gt;
&lt;li&gt;Create a new file with some content&lt;/li&gt;
&lt;li&gt;Add one commit to the master branch where we add the file&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This will give us enough to push the repository to github as a remote&lt;/p&gt;
&lt;h2&gt;How?&lt;/h2&gt;
&lt;p&gt;Our script does the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Create a &lt;code&gt;HEAD&lt;/code&gt; file at &lt;code&gt;.git/HEAD&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create blob -&amp;gt; tree -&amp;gt; commit objects in &lt;code&gt;.git/objects&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Create a ref file at &lt;code&gt;.git/refs/heads/master&lt;/code&gt; to point to the commit we
created&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now we go into detail for each of the steps outlined above.&lt;/p&gt;
&lt;h3&gt;The HEAD&lt;/h3&gt;
&lt;p&gt;The HEAD is a pointer to a reference which is a currently checked out in our
repo. We can change where HEAD points to using commands like &lt;code&gt;git checkout&lt;/code&gt; or
&lt;code&gt;git switch&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;We point HEAD to the &lt;code&gt;master&lt;/code&gt; branch. Here is the code to do that:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;err := os.WriteFile(filepath.Join(&amp;quot;.git&amp;quot;, &amp;quot;HEAD&amp;quot;), []byte(&amp;quot;ref: refs/heads/master\n&amp;quot;), 0644)
if err != nil {
    log.Fatal(err)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here HEAD points to the reference master. &lt;code&gt;.git/refs/heads/master&lt;/code&gt; will tell us
where master actually points to&lt;/p&gt;
&lt;h3&gt;Creating the right objects&lt;/h3&gt;
&lt;p&gt;An object is something that is stored on the disk and can be referred to using a
key. Git stores files, commits, tags and many other things as objects. The three
types of objects relevant to our discussion are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;blob&lt;/strong&gt;: git represents file contents as blobs. This is the foundation object
in many ways&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;tree&lt;/strong&gt;: this represents a directory on the filesystem. Trees can contain
other trees and blobs. The representation is similar to a UNIX filesystem&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;commit&lt;/strong&gt;: this object stores a snapshot of the git repo and contains
information like the tree which it points to, the author of the commit, a
message describing why the commit was made etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Objects are stored in the &lt;code&gt;.git/objects&lt;/code&gt; directory. You can go to any git repo
and see any object using the following plumbing command:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;git cat-file -p 7108f7ecb345ee9d0084193f147cdad4d2998293
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The long string at the end is the object hash which is the key mentioned
earlier. This is the SHA-1 hash of the contents of the objects and it is stored
on disk like so:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;.git/objects/71/08f7ecb345ee9d0084193f147cdad4d2998293
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But running the above cat-file command shows us a bunch of gibberish. This is
because git uses &lt;a href=&quot;https://en.wikipedia.org/wiki/Zlib&quot;&gt;zlib&lt;/a&gt; to compress the
contents before writing the objects to disk. So, the order is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use some logic to get the contents of the object (more on this later)&lt;/li&gt;
&lt;li&gt;Compress the contents using zlib&lt;/li&gt;
&lt;li&gt;Write the compressed contents to a file path constructed using the hash of the
uncompressed contents&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each object comprises of two parts, the header and the content. The header is
concatenated with the content to get the final object that is stored on disk
after compression. The header for a tree object looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;header = &amp;quot;tree &amp;quot; + strconv.Itoa(len([]byte(content))) + &amp;quot;\000&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The header format looks like &lt;code&gt;&amp;lt;objectType&amp;gt; len(content)\0&lt;/code&gt; (\0 is the null
byte). Here &lt;em&gt;content&lt;/em&gt; is the stuff that follows \0. Replace the word &quot;tree&quot; with
&quot;blob&quot; and &quot;commit&quot; to get the header format for blobs and commits respectively&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;func getObject(content, objectType string) (string, bytes.Buffer) {
	var header string
	var store string
	switch objectType {
	case &amp;quot;blob&amp;quot;:
		header = &amp;quot;blob &amp;quot; + strconv.Itoa(len([]byte(content))) + &amp;quot;\000&amp;quot;
	case &amp;quot;tree&amp;quot;:
		header = &amp;quot;tree &amp;quot; + strconv.Itoa(len([]byte(content))) + &amp;quot;\000&amp;quot;
	case &amp;quot;commit&amp;quot;:
		header = &amp;quot;commit &amp;quot; + strconv.Itoa(len([]byte(content))) + &amp;quot;\000&amp;quot;
	default:
		fmt.Println(&amp;quot;Unhandled object type&amp;quot;, objectType)
	}
	store = header + content

	// the content of the object stored on disk
	var zlibContent bytes.Buffer
	w := zlib.NewWriter(&amp;amp;zlibContent)
	w.Write([]byte(store))
	w.Close()

	// used for creating object filename
	hash := sha1.Sum([]byte(store))
	return hex.EncodeToString(hash[:]), zlibContent
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The getObject function takes in some content and returns the zlib compressed
data and SHA-1 hash. We call this function for each of the three types of
objects. Let&#39;s look at the content for each type of object.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;content := &amp;quot;what is up, doc?\n&amp;quot;
blobHash, zlibContent := getObject(content, &amp;quot;blob&amp;quot;)
err = writeObject(filepath.Join(objectsDir, blobHash[0:2]), blobHash[2:], zlibContent.Bytes())
if err != nil {
	log.Fatal(&amp;quot;failed to write blob object&amp;quot;, err)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The blob stores the contents &quot;what is up, doc?\n&quot;. We write the contents to disk
using the writeObject function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;func writeObject(dirName, fileName string, content []byte) error
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We construct the directory name by using the first two characters of the SHA1
hash of the object along with the base objects directory&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;var objectsDir = filepath.Join(&amp;quot;.git&amp;quot;, &amp;quot;objects&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Content of the &lt;em&gt;tree&lt;/em&gt; object:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// concat hash of previous blob in binary format: https://stackoverflow.com/a/33039114
decoded, _ := hex.DecodeString(blobHash)
content = &amp;quot;100644 hello.txt\000&amp;quot; + string(decoded[:])
treeHash, zlibContent := getObject(content, &amp;quot;tree&amp;quot;)
err = writeObject(filepath.Join(objectsDir, treeHash[0:2]), treeHash[2:], zlibContent.Bytes())
if err != nil {
    log.Fatal(&amp;quot;failed to write tree object&amp;quot;, err)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we add a blob called hello.txt with permission 100644. The permissions are
similar to UNIX ones, except they are very restrictive (100644 for blobs, 040000
for trees etc.)&lt;/p&gt;
&lt;p&gt;The content format for trees is a little different from those of blobs and
commits:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;tree [content size]\0[Entries having references to other trees and blobs]
[mode] [file/folder name]\0[SHA-1 of referencing blob or tree]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the SHA-1 of referencing blobs/trees should be in binary format. Refer
&lt;a href=&quot;https://stackoverflow.com/a/33039114&quot;&gt;here&lt;/a&gt; for more details&lt;/p&gt;
&lt;p&gt;If we have more than one entry for referencing blob/tree, it should be sorted
lexicographically based on path&lt;/p&gt;
&lt;p&gt;More information can be found on this
&lt;a href=&quot;https://stackoverflow.com/questions/14790681/what-is-the-internal-format-of-a-git-tree-object&quot;&gt;stackoverflow&lt;/a&gt;
post&lt;/p&gt;
&lt;p&gt;The commit contents are similar to blobs:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;content = &amp;quot;tree &amp;quot; + treeHash + &amp;quot;\nauthor Siddharth Singh &amp;lt;me@s1dsq.com&amp;gt; 1708260537 +0530\ncommitter Siddharth Singh &amp;lt;me@s1dsq.com&amp;gt; 1708260537 +0530\n\nAdd hello.txt\n&amp;quot;
commitHash, zlibContent := getObject(content, &amp;quot;commit&amp;quot;)
err = writeObject(filepath.Join(objectsDir, commitHash[0:2]), commitHash[2:], zlibContent.Bytes())
if err != nil {
    log.Fatal(&amp;quot;failed to write commit object&amp;quot;, err)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Commit hashes are non-deterministic as they contain timestamp which can change.
I have used fixed timestamp to make the hash deterministic and reproducible&lt;/p&gt;
&lt;h3&gt;Point master to the commit&lt;/h3&gt;
&lt;p&gt;A commit is freestanding entity in the object universe. We point hashes to human
readable references to help us keep track of a chain of commits. Here is the
code to do it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-go&quot;&gt;// point &amp;quot;master&amp;quot; ref to the commit hash we just created
createDir(&amp;quot;.git/refs/heads&amp;quot;)
err = os.WriteFile(filepath.Join(&amp;quot;.git&amp;quot;, &amp;quot;refs&amp;quot;, &amp;quot;heads&amp;quot;, &amp;quot;master&amp;quot;), []byte(commitHash), 0644)
if err != nil {
    log.Fatal(&amp;quot;failed to write refs/heads&amp;quot;, err)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Running &lt;code&gt;git log&lt;/code&gt; shows us the commit we just created&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Add a git remote of your choice like and push to it:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;language-sh&quot;&gt;git remote add origin git@github.com:s1dsq/basic-git-repo.git
git push -u origin master
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check the repo on github to see that we have a file called hello.txt on the
master branch with one commit on it&lt;/p&gt;
&lt;p&gt;The go script used in the post is available &lt;a href=&quot;https://github.com/s1dsq/primitive-git&quot;&gt;here&lt;/a&gt;&lt;/p&gt;</content>
		<link href="https://s1dsq.github.io/git-internals"/>
		<id>https://s1dsq.github.io/git-internals</id>
		<updated>2024-03-24T10:00:00Z</updated>
		<published>2024-03-24T10:00:00Z</published>
	</entry>
	<entry>
		<title>Firecracker: Lightweight Virtualization for Serverless Applications</title>
		<content type="html">&lt;h1&gt;Firecracker: Lightweight Virtualization for Serverless Applications&lt;/h1&gt;
&lt;p&gt;2025-04-23&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.usenix.org/system/files/nsdi20-paper-agache.pdf&quot;&gt;Firecracker&lt;/a&gt; is
AWS&#39; &lt;a href=&quot;https://firecracker-microvm.github.io/&quot;&gt;open source&lt;/a&gt; virtual machine
monitor used in it&#39;s serverless functions and container offerings (Lambda and
Fargate)&lt;/p&gt;
&lt;p&gt;Firecracker is a good case study because of it&#39;s small(er) scope than many other
VMMs out there. It
&lt;a href=&quot;https://github.com/firecracker-microvm/firecracker/blob/main/SPECIFICATION.md&quot;&gt;promises&lt;/a&gt;
fast VM startup, minimal overhead and strong security among other things.&lt;/p&gt;
&lt;h2&gt;The need for a new VMM&lt;/h2&gt;
&lt;p&gt;Serverless compute allows you to run workloads on rented computers without
worrying about managing them. This is a good business to be in as cloud
providers. Multi-tenancy (running multiple workloads on the same computer) is a
lucrative business model but poses challenges:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Security - one workload should not be able to access data from another&lt;/li&gt;
&lt;li&gt;Performance - should not decrease due to resource sharing (noisy neighbour
effect)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Operating system virtualization has been explored before. The linux kernel has
builtin mechanisms for this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cgroups&lt;/code&gt; - grouping process and managing resource usage&lt;/li&gt;
&lt;li&gt;&lt;code&gt;namespaces&lt;/code&gt; - separate kernel resources like PIDs&lt;/li&gt;
&lt;li&gt;&lt;code&gt;seccomp-bpf&lt;/code&gt; - controlling access to syscalls&lt;/li&gt;
&lt;li&gt;&lt;code&gt;chroot&lt;/code&gt; - providing an isolated filesystem&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This provides strong isolation but we are trading off security (due to workloads
sharing the same kernel) and code compatibility (customers should be able to run
arbitrary linux binaries)&lt;/p&gt;
&lt;p&gt;Hypervisor based virtualiztion solves for the two issues but carries with it an
performance overhead.&lt;/p&gt;
&lt;p&gt;Firecracker was built to have the best of both hypervisor virtualization and OS
level containers - you get performance and isolation together&lt;/p&gt;
&lt;h2&gt;VMM&lt;/h2&gt;
&lt;p&gt;Firecracker VMM uses the KVM infrastructure built into linux kernel to provide
minimal virtual machines. It relies on components built into linux rather than
re-implementing their own. Eg: block I/O is passed through to the kernel,
TUN/TAP is used as virtual network interfaces.&lt;/p&gt;
&lt;h3&gt;Device model&lt;/h3&gt;
&lt;p&gt;A minimal set of devices are emulated:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;serial ports&lt;/li&gt;
&lt;li&gt;partial PS/2 keyboard controller via i8042&lt;/li&gt;
&lt;li&gt;network and block devices: virtio (an open API standard) is used for exposing
emulated devices. Storage only supports block devices and not filesystem as
the implementation can be complex and also increases the security risks&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;API&lt;/h3&gt;
&lt;p&gt;Firecracker exposes REST API as a means to specify guest kernel, boot arguments,
network configs, storage configs, guest machine configs and cpuid, logging,
metrics, rate limiters etc.&lt;/p&gt;
&lt;h3&gt;Rate limiting and performance&lt;/h3&gt;
&lt;p&gt;The APIs can be used to describe the cores and memory required by the VMs as
well as set things like cpuids. Firecracker does not emulate missing CPU
functionality and cpuids are more used for hiding things from the VMs making the
fleet of heterogenous computers appear homogenous&lt;/p&gt;
&lt;p&gt;Builtin rate limiting is applied to storage (IOPS) and networking (PPS). They
can also be configured via the REST APIs to change things on demand when needed.
The storage / networking components are rate limited to allow for control plane
operations and ensuring that a small numbers of VMs don&#39;t hijack these resources&lt;/p&gt;
&lt;h3&gt;Jailer&lt;/h3&gt;
&lt;p&gt;An important additional security measure is wrapping the firecracker VMM around
a jailer process that sandboxes the VMM and:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;runs it in a &lt;em&gt;chroot&lt;/em&gt; environment&lt;/li&gt;
&lt;li&gt;isolates it in &lt;em&gt;pid&lt;/em&gt; and networking namespaces&lt;/li&gt;
&lt;li&gt;drops privileges&lt;/li&gt;
&lt;li&gt;sets a restrictive &lt;em&gt;seccomp_bpf&lt;/em&gt; profile - whitelisting some syscalls&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;In AWS Lambda&lt;/h2&gt;
&lt;p&gt;Lambda provides &lt;em&gt;serverless functions&lt;/em&gt; which runs functions in response to
events in your code. Lambda functions run within a sandbox, which provides
minimal Linux userland and some libraries and utilities.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;../public/images/lambda_worker.png&quot; alt=&quot;worker&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The execution of customer code happens inside the lambda worker fleet
(architecture shown above). Workers provide a &lt;em&gt;slot&lt;/em&gt; which provides pre-loaded
environments for executing functions.&lt;/p&gt;
&lt;p&gt;Each worker can run hundreds or thousands of MicroVMs (each having one slot).
Along with a minimal linux userland and kernel each MicroVM contains a shim
process which communicates with the outside control plane. One firecracker
process is launched per MicroVM, responsible for creating and managing the
MicroVM and providing device emulation and handling VM exits.&lt;/p&gt;
&lt;p&gt;The shim process communicates with the &quot;Micro Manager&quot; via TCP/IP. The
micro-manager is responsible for managing the firecracker process inside the
worker. The manager communicates with the rest of the lambda stack to provide
status updates, sending payload / error messages etc. Communication between the
micro-manager and firecracker add some overhead but keeps the system loosely
coupled. This communication protocol is an important boundary because it
separates the multi-tenant control plane from the single tenant / single
function MicroVM&lt;/p&gt;
&lt;p&gt;The MicroVM also has processes for logging, monitoring and the like that send
updates to humans and automated systems&lt;/p&gt;
&lt;p&gt;The micro-manager also does optimizations such as pre-booting VMs to keep the
lambda hot-path fast&lt;/p&gt;
&lt;h2&gt;Evaluation&lt;/h2&gt;
&lt;p&gt;Firecracker set out with a couple of goals which it achieves:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Isolation&lt;/strong&gt;: multiple workloads can run on the same hardware through
virtualization&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Overhead and density&lt;/strong&gt;: overhead is as low as 3% for memory and minimal for CPU&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt;: block IO and network performance can be improved but are
sufficient for Lambda and Fargate&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compatibility&lt;/strong&gt;: firecracker can run unmodified linux kernel and userland&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fast switching&lt;/strong&gt;: boot times are as low as 150ms, so switching is fast&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Soft allocation&lt;/strong&gt;: memory and cpu are oversubscribed by multiple orders of
magnitude&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For some of the comparisons between Firecracker and other VMMs on metrics like
boot times, overhead and IO performance check out the firecracker paper&lt;/p&gt;</content>
		<link href="https://s1dsq.github.io/firecracker"/>
		<id>https://s1dsq.github.io/firecracker</id>
		<updated>2025-04-23T10:00:00Z</updated>
		<published>2025-04-23T10:00:00Z</published>
	</entry>
</feed>
